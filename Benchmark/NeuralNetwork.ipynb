{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Notebook that runs a neutral network on the adult and student performance dataset without annoymisation.\n",
    "Supposed to be a benchmark for the anonimised data sets.\n",
    "\"\"\"\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "\n",
    "# import modules\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Please note that the data has been cleaned (=no missing/NaN values) in advance.\n",
    "\"\"\"\n",
    "\n",
    "# load data\n",
    "adult_train = pd.read_csv('/Users/pepijndereus/Desktop/Thesis/Data/Adult/Adult_train.csv')\n",
    "adult_val = pd.read_csv('/Users/pepijndereus/Desktop/Thesis/Data/Adult/Adult_val.csv')\n",
    "\n",
    "def preprocess_dataset(adult):\n",
    "    # make binary labels for income column\n",
    "    adult['income'] = adult['income'].str.replace('<=50K', '0')\n",
    "    adult['income'] = adult['income'].str.replace('>50K', '1')\n",
    "    adult['income'] = adult['income'].astype(int)\n",
    "\n",
    "    # make array with labels, remove labels from dataframe\n",
    "    labels = adult['income'].copy()\n",
    "    labels = np.array(labels)\n",
    "    adult = adult.drop(['income'], axis=1)\n",
    "\n",
    "    # use Min-max scaling for continuous features\n",
    "    adult[['age','capital_gain','capital_loss','hr_per_week']] = MinMaxScaler().fit_transform(adult[['age','capital_gain','capital_loss','hr_per_week']])\n",
    "\n",
    "    # use One-hot encoding for categorial features\n",
    "    adult = pd.get_dummies(adult,columns = ['type_employer','education','marital','occupation','relationship','race','sex','country'])\n",
    "    \n",
    "    return adult, labels\n",
    "\n",
    "# apply preprocessing to training and validation set\n",
    "adult_train, labels_train = preprocess_dataset(adult_train)\n",
    "adult_val, labels_val = preprocess_dataset(adult_val)\n",
    "\n",
    "set(adult_train.columns).difference(adult_val.columns)\n",
    "\n",
    "# since only 1 entry for entire set, remove this column\n",
    "adult_train.drop('country_Holand-Netherlands', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the neural network..\n",
      "\n",
      "\n",
      "Prediction accuracy:\n",
      "\n",
      "471/471 [==============================] - 1s 1ms/step - loss: 0.3276 - accuracy: 0.8459\n",
      "\n",
      "The loss is 0.32756349444389343, and the accuracy is 0.8458831310272217\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now that the data is preprocessed for the neural network, we run the neural net.\n",
    "\"\"\"\n",
    "\n",
    "# create neural network with keras sequential model\n",
    "NeuralNet = Sequential()\n",
    "\n",
    "# add 3 layers, one input, one output and one hidden layer\n",
    "NeuralNet.add(Dense(6, activation = 'relu'))\n",
    "NeuralNet.add(Dense(6, activation = 'relu'))\n",
    "NeuralNet.add(Dense(1, activation = 'sigmoid'))\n",
    "NeuralNet.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# train the network with training set and training labels\n",
    "print(\"Training the neural network..\\n\")                   \n",
    "NeuralNet.fit(adult_train, labels_train, batch_size = 10, epochs = 20, verbose=0)\n",
    "\n",
    "# validate the network with the validation set and labels\n",
    "print(\"\\nPrediction accuracy:\\n\")\n",
    "predication = NeuralNet.predict(adult_val)\n",
    "\n",
    "# print the accuracy\n",
    "loss, accuracy = NeuralNet.evaluate(adult_val, labels_val)\n",
    "print(f\"\\nThe loss is {loss}, and the accuracy is {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "The code above was created with help of the following sources:\n",
    "\n",
    "* https://www.kaggle.com/code/ritvikkhanna09/simple-neural-networks-using-keras/notebook#Training-the-Neural-Network , accessed at 13-04-2022\n",
    "\n",
    "* https://github.com/DeepakGunturu/Adult-Dataset-Classification/blob/main/classifiers.py , accessed at 11-04-2022"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
