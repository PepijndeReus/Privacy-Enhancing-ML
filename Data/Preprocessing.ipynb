{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59299568",
   "metadata": {},
   "source": [
    "Since the data should be preprocessed for the Neural Network, k-Nearest Neighbours and the Logistic Regression in the same way, this notebook runs the preprocessing. The data will be saved as .csv files that can than be used to apply machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6500d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78cb606",
   "metadata": {},
   "source": [
    "## Adult data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a905ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Please note that the data has been cleaned (=no missing/NaN values) in advance.\n",
    "This is done by Cleaning.ipynb\n",
    "\"\"\"\n",
    "\n",
    "# change directory\n",
    "os.chdir('Adult')\n",
    "\n",
    "# load data\n",
    "adult_train = pd.read_csv('Adult_train.csv')\n",
    "adult_val = pd.read_csv('Adult_val.csv')\n",
    "\n",
    "def preprocess_dataset(adult):\n",
    "    # make binary labels for income column\n",
    "    adult['income'] = adult['income'].str.replace('<=50K', '0')\n",
    "    adult['income'] = adult['income'].str.replace('>50K', '1')\n",
    "    adult['income'] = adult['income'].astype(int)\n",
    "\n",
    "    # make array with labels, remove labels from dataframe\n",
    "    labels = adult['income'].copy()\n",
    "    # labels = np.array(labels)\n",
    "    adult = adult.drop(['income'], axis=1)\n",
    "\n",
    "    # use Min-max scaling for continuous features\n",
    "    adult[['age','capital_gain','capital_loss','hr_per_week']] = MinMaxScaler().fit_transform(adult[['age','capital_gain','capital_loss','hr_per_week']])\n",
    "\n",
    "    # use One-hot encoding for categorial features\n",
    "    adult = pd.get_dummies(adult,columns = ['type_employer','education','marital','occupation','relationship','race','sex','country'])\n",
    "    \n",
    "    return adult, labels\n",
    "\n",
    "# apply preprocessing to training and validation set\n",
    "adult_train, labels_train = preprocess_dataset(adult_train)\n",
    "adult_val, labels_val = preprocess_dataset(adult_val)\n",
    "\n",
    "set(adult_train.columns).difference(adult_val.columns)\n",
    "\n",
    "# since only 1 entry for entire set, remove this column\n",
    "adult_train.drop('country_Holand-Netherlands', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ac0e5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adult training set saved to csv!\n",
      "\n",
      "Adult validation set saved to csv!\n"
     ]
    }
   ],
   "source": [
    "# now save the .csv files\n",
    "adult_train.to_csv('Adult_train_data.csv', index=False)\n",
    "labels_train.to_csv('Adult_train_labels.csv', index=False)\n",
    "print(\"Adult training set saved to csv!\\n\")\n",
    "\n",
    "adult_val.to_csv('Adult_val_data.csv', index=False)\n",
    "labels_val.to_csv('Adult_val_labels.csv', index=False)\n",
    "print(\"Adult validation set saved to csv!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7575a821",
   "metadata": {},
   "source": [
    "## Student performance data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9a3e7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set: 519, length of validation set: 130\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# set path\n",
    "os.chdir('../Student')\n",
    "\n",
    "# load data\n",
    "student = pd.read_csv('student-por.csv', delimiter=';')\n",
    "\n",
    "# use Min-max scaling for continuous features\n",
    "student[['age','absences','G1','G2','G3']] = MinMaxScaler().fit_transform(student[['age','absences','G1','G2','G3']])\n",
    "\n",
    "student_data = student.loc[:,student.columns != 'G3']\n",
    "student_target = student['G3']\n",
    "\n",
    "# use One-hot encoding for categorial features\n",
    "columns = student_data.columns.values.tolist()\n",
    "continous_columns = ['age','absences','G1','G2']\n",
    "categorial_columns = [feature for feature in columns if feature not in continous_columns]\n",
    "student_data = pd.get_dummies(student_data, columns = categorial_columns)\n",
    "\n",
    "# split into training and validation set\n",
    "student_train = student_data[:int(len(student_data) * 0.8)]\n",
    "student_val = student_data[int(len(student_data) * 0.8):]\n",
    "grade_train = student_target[:int(len(student_data) * 0.8)]\n",
    "grade_val = student_target[int(len(student_data) * 0.8):]\n",
    "\n",
    "# check if sets are equal\n",
    "print(f\"Length of training set: {len(student_train)}, length of validation set: {len(student_val)}\")\n",
    "print(len(student_train) == len(grade_train))\n",
    "print(len(student_val) == len(grade_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7258847d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student performance training set saved to csv!\n",
      "\n",
      "Student performance validation set saved to csv!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now save the .csv files\n",
    "student_train.to_csv('student_train_data.csv', index=False)\n",
    "grade_train.to_csv('student_train_grade.csv', index=False)\n",
    "print(\"Student performance training set saved to csv!\\n\")\n",
    "\n",
    "student_val.to_csv('student_val_data.csv', index=False)\n",
    "grade_val.to_csv('student_val_grade.csv', index=False)\n",
    "print(\"Student performance validation set saved to csv!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
